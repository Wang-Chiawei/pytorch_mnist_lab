{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYG8xzuLr-HI"
      },
      "source": [
        "# [HW] MNIST\n",
        "\n",
        "https://www.kaggle.com/competitions/mnist-sai"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JqIcnWvwMpc"
      },
      "source": [
        "# Basic module\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm # progress bar\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LsiyFhmR_2N"
      },
      "source": [
        "# print version of PyTorch\n",
        "torch.__version__, torchvision.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDg9Aq-aSCNF"
      },
      "source": [
        "# Define Parameters\n",
        "NUM_CLASS = 10\n",
        "IMG_SIZE = 28\n",
        "CHANNEL = 1\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXajqeGESoSn"
      },
      "source": [
        "#### Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNrVIx0k2Ivm"
      },
      "source": [
        "# download from google drive\n",
        "!pip install --upgrade gdown\n",
        "!gdown --id '1Pb9lxPjXBEq4O8KMzdemqehRtp_jr-Wy' --output mnist.npz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, label):\n",
        "        self.x_data = data\n",
        "        self.y_label = label\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.transforms.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.x_data[idx]\n",
        "        img = self.transform(img)\n",
        "\n",
        "        label = self.y_label[idx]\n",
        "        label = torch.tensor(label, dtype=torch.long)\n",
        "        return img, label"
      ],
      "metadata": {
        "id": "P56egp7gGz6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data from file\n",
        "with np.load('mnist.npz', allow_pickle=True) as f:\n",
        "    x_train, y_train = f['x_train'], f['y_train']\n",
        "    x_test = f['x_test']\n",
        "\n",
        "all_dataset = MNISTDataset(x_train, y_train)"
      ],
      "metadata": {
        "id": "tk-i3LODIGvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0PDCZGkwMpi"
      },
      "source": [
        "# number of data\n",
        "len(all_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHAhmYzz23TZ"
      },
      "source": [
        "# split dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_ds, val_ds = train_test_split(all_dataset,\n",
        "                                    test_size=0.2,\n",
        "                                    random_state=5566)\n",
        "\n",
        "len(train_ds), len(val_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get 1 data\n",
        "x, y = train_ds[0]\n",
        "print(type(x), type(y))\n",
        "print(x.shape, y.shape)"
      ],
      "metadata": {
        "id": "_wSmtPf1Iu1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_ds,\n",
        "                                           BATCH_SIZE,\n",
        "                                           shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_ds,\n",
        "                                         BATCH_SIZE)"
      ],
      "metadata": {
        "id": "ubx96lYUK-2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8STKvep1eC4v"
      },
      "source": [
        "#### Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtOqbCgkd9PZ"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "9baqfhIEKm0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(\n",
        "    params=model.parameters(),\n",
        "    lr=1e-2, # learning rate\n",
        ")"
      ],
      "metadata": {
        "id": "dvs5lcCgKvaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset) # number of samples\n",
        "    num_batches = len(dataloader) # batches per epoch\n",
        "\n",
        "    model.train() # to training mode.\n",
        "    epoch_loss, epoch_correct = 0, 0\n",
        "    for batch_i, (x, y) in enumerate(tqdm(dataloader, leave=False)):\n",
        "        x, y = x.to(device), y.to(device) # move data to device\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Compute prediction loss\n",
        "        pred = model(x)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Optimization by gradients\n",
        "        loss.backward() # backpropagation to compute gradients\n",
        "        optimizer.step() # update model params\n",
        "\n",
        "        # write to logs\n",
        "        epoch_loss += loss.item() # tensor -> python value\n",
        "        # (N, Class)\n",
        "        epoch_correct += (pred.argmax(dim=1) == y).sum().item()\n",
        "\n",
        "    # return avg loss of epoch, acc of epoch\n",
        "    return epoch_loss/num_batches, epoch_correct/size\n",
        "\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset) # number of samples\n",
        "    num_batches = len(dataloader) # batches per epoch\n",
        "\n",
        "    model.eval() # model to test mode.\n",
        "    epoch_loss, epoch_correct = 0, 0\n",
        "\n",
        "    # No gradient for test data\n",
        "    with torch.no_grad():\n",
        "        for batch_i, (x, y) in enumerate(tqdm(dataloader, leave=False)):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            # Compute prediction loss\n",
        "            pred = model(x)\n",
        "            loss = loss_fn(pred, y)\n",
        "\n",
        "            # write to logs\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_correct += (pred.argmax(1) == y).sum().item()\n",
        "\n",
        "    return epoch_loss/num_batches, epoch_correct/size"
      ],
      "metadata": {
        "id": "aHV0W8VcLX3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "logs = {\n",
        "    'train_loss': [], 'train_acc': [],\n",
        "    'val_loss': [], 'val_acc': []\n",
        "}\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    train_loss, train_acc = train(train_loader, model, loss_fn, optimizer)\n",
        "    val_loss, val_acc = test(val_loader, model, loss_fn)\n",
        "\n",
        "    print(f'EPOCH: {epoch} \\\n",
        "    train_loss: {train_loss:.4f}, train_acc: {train_acc:.3f} \\\n",
        "    val_loss: {val_loss:.4f}, val_acc: {val_acc:.3f} ')\n",
        "\n",
        "    logs['train_loss'].append(train_loss)\n",
        "    logs['train_acc'].append(train_acc)\n",
        "    logs['val_loss'].append(val_loss)\n",
        "    logs['val_acc'].append(val_acc)"
      ],
      "metadata": {
        "id": "3qJDXZb_LaxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Logs"
      ],
      "metadata": {
        "id": "RvOuxxNvLllZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMyM477lwMp8"
      },
      "source": [
        "plt.plot(logs['train_loss'])\n",
        "plt.plot(logs['val_loss'])\n",
        "plt.legend(['train_loss', 'val_loss'])\n",
        "plt.title('loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(logs['train_acc'])\n",
        "plt.plot(logs['val_acc'])\n",
        "plt.legend(['train_acc', 'val_acc'])\n",
        "plt.title('Acc')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ADN0K5aPL0Zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLGijtIyzrf9"
      },
      "source": [
        "#### Generate file for Kaggle\n",
        "\n",
        "https://www.kaggle.com/competitions/mnist-sai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTTestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.x_data = data\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.transforms.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.x_data[idx]\n",
        "        img = self.transform(img)\n",
        "        return img\n",
        "\n",
        "test_ds = MNISTTestDataset(x_test)\n",
        "test_loader = torch.utils.data.DataLoader(test_ds, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "_KvKi_tGL7wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict all data\n",
        "y_pred = []\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x in test_loader:\n",
        "        x = x.to(device)\n",
        "        pred = model(x)\n",
        "        y_pred.append(pred)\n",
        "\n",
        "y_pred = torch.cat(y_pred).argmax(1).cpu().numpy()\n",
        "y_pred.shape"
      ],
      "metadata": {
        "id": "ySyQiEDsMOOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPX5mGWfzswS"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df['Id'] = [str(i) for i in range(len(x_test))]\n",
        "df['Category'] = y_pred\n",
        "df.to_csv('result.csv', index=None)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guBMgShGz7jq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}